{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhl4CwGLuofi"
      },
      "source": [
        "BloomTech Data Science\n",
        "\n",
        "*Unit 2, Sprint 2, Module 3*\n",
        "\n",
        "---\n",
        "<p style=\"padding: 10px; border: 2px solid red;\">\n",
        "    <b>Before you start:</b> Today is the day you should submit the dataset for your Unit 2 Build Week project. You can review the guidelines and make your submission in the Build Week course for your cohort on Canvas.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1L4OgGIuofy"
      },
      "source": [
        "# Module Project: Hyperparameter Tuning\n",
        "\n",
        "This sprint, the module projects will focus on creating and improving a model for the Tanazania Water Pump dataset. Your goal is to create a model to predict whether a water pump is functional, non-functional, or needs repair.\n",
        "\n",
        "Dataset source: [DrivenData.org](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/).\n",
        "\n",
        "## Directions\n",
        "\n",
        "The tasks for this project are as follows:\n",
        "\n",
        "- **Task 1:** Use `wrangle` function to import training and test data.\n",
        "- **Task 2:** Split training data into feature matrix `X` and target vector `y`.\n",
        "- **Task 3:** Establish the baseline accuracy score for your dataset.\n",
        "- **Task 4:** Build `clf_dt`.\n",
        "- **Task 5:** Build `clf_rf`.\n",
        "- **Task 6:** Evaluate classifiers using k-fold cross-validation.\n",
        "- **Task 7:** Tune hyperparameters for best performing classifier.\n",
        "- **Task 8:** Print out best score and params for model.\n",
        "- **Task 9:** Create `submission.csv` and upload to Kaggle.\n",
        "\n",
        "You should limit yourself to the following libraries for this project:\n",
        "\n",
        "- `category_encoders`\n",
        "- `matplotlib`\n",
        "- `pandas`\n",
        "- `pandas-profiling`\n",
        "- `sklearn`\n",
        "\n",
        "# I. Wrangle Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwSpZl_uuofv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c1f35b6-ebc4-442f-d857-c35cdfa114a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: category_encoders==2.* in /usr/local/lib/python3.7/dist-packages (2.3.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders==2.*) (1.7.3)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders==2.*) (1.1.5)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders==2.*) (0.5.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders==2.*) (1.19.5)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders==2.*) (0.10.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders==2.*) (1.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders==2.*) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders==2.*) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->category_encoders==2.*) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders==2.*) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders==2.*) (3.0.0)\n",
            "Requirement already satisfied: pandas-profiling==2.* in /usr/local/lib/python3.7/dist-packages (2.13.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==2.*) (1.1.0)\n",
            "Requirement already satisfied: matplotlib>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==2.*) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==2.*) (2.26.0)\n",
            "Requirement already satisfied: visions[type_image_path]==0.7.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==2.*) (0.7.1)\n",
            "Requirement already satisfied: confuse>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==2.*) (1.7.0)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==2.*) (4.62.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==2.*) (1.7.3)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==2.*) (21.2.0)\n",
            "Requirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==2.*) (2.11.3)\n",
            "Requirement already satisfied: tangled-up-in-unicode>=0.0.6 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==2.*) (0.2.0)\n",
            "Requirement already satisfied: phik>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==2.*) (0.12.0)\n",
            "Requirement already satisfied: htmlmin>=0.1.12 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==2.*) (0.1.12)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==2.*) (1.19.5)\n",
            "Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==2.*) (0.5.0)\n",
            "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==2.*) (1.1.5)\n",
            "Requirement already satisfied: seaborn>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling==2.*) (0.11.2)\n",
            "Requirement already satisfied: multimethod==1.4 in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.1->pandas-profiling==2.*) (1.4)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.1->pandas-profiling==2.*) (2.6.3)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.1->pandas-profiling==2.*) (1.3.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.1->pandas-profiling==2.*) (7.1.2)\n",
            "Requirement already satisfied: imagehash in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.1->pandas-profiling==2.*) (4.2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from confuse>=1.0.0->pandas-profiling==2.*) (3.13)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.11.1->pandas-profiling==2.*) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.0->pandas-profiling==2.*) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.0->pandas-profiling==2.*) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.0->pandas-profiling==2.*) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.0->pandas-profiling==2.*) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3->pandas-profiling==2.*) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.2.0->pandas-profiling==2.*) (1.15.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling==2.*) (2.0.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling==2.*) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling==2.*) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling==2.*) (2021.10.8)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.7/dist-packages (from imagehash->visions[type_image_path]==0.7.1->pandas-profiling==2.*) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install category_encoders==2.*\n",
        "!pip install pandas-profiling==2.*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from category_encoders import OrdinalEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDbLrXhSvEs5",
        "outputId": "04552729-4898-4923-f4fa-66f3dcbb638e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_nK1z7Nxfce",
        "outputId": "7cf578b4-7adb-48b8-dcfe-2fd209bff467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Kaggle Challenge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-ZKwt_HyYrO",
        "outputId": "ec325d33-398d-410d-b16c-e3d2f04f102d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Kaggle Challenge\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMEMo_Pqyer-",
        "outputId": "7e3ad72f-7a63-4b25-953c-56f52514e617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json\t    sample_submission.csv  train_features.csv\n",
            "new_submission.csv  test_features.csv\t   train_labels.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_qsCtXyuofz"
      },
      "outputs": [],
      "source": [
        "def wrangle(fm_path, tv_path=None):\n",
        "    if tv_path:\n",
        "        df = pd.merge(pd.read_csv(fm_path, \n",
        "                                  na_values=[0, -2.000000e-08],\n",
        "                                  parse_dates = ['date_recorded']),\n",
        "                      pd.read_csv(tv_path)).set_index('id')\n",
        "    else:\n",
        "        df = pd.read_csv(fm_path, \n",
        "                         na_values=[0, -2.000000e-08],\n",
        "                         parse_dates = ['date_recorded'],\n",
        "                         index_col='id')\n",
        "\n",
        "    # Drop constant columns\n",
        "    df.drop(columns=['recorded_by'], inplace=True)\n",
        "\n",
        "    # Drop HCCCs\n",
        "    cutoff = 100\n",
        "    drop_cols = [col for col in df.select_dtypes('object').columns\n",
        "                 if df[col].nunique() > cutoff]\n",
        "    df.drop(columns=drop_cols, inplace=True)\n",
        "\n",
        "    # Drop duplicate columns\n",
        "    dupe_cols = [col for col in df.head(15).T.duplicated().index\n",
        "                 if df.head(15).T.duplicated()[col]]\n",
        "    df.drop(columns=dupe_cols, inplace=True)  \n",
        "    \n",
        "        #Make pump_age feature\n",
        "    df['pump_age'] = df['date_recorded'].dt.year - df['construction_year']\n",
        "\n",
        "    #drop columns\n",
        "    df = df.drop(columns = ['date_recorded'])\n",
        "    df = df.drop(columns = ['num_private'])\n",
        "    df = df.drop(columns = ['management_group'])\n",
        "    df = df.drop(columns = ['source_type'])\n",
        "    df = df.drop(columns = ['public_meeting'])\n",
        "    \n",
        "   \n",
        "\n",
        "    #one hot encoding columns\n",
        "    pd.get_dummies(df['quantity'], prefix = 'quantity')\n",
        "    df = pd.concat([df,pd.get_dummies(df['quantity'], prefix = 'quantity')],axis=1)\n",
        "    df = df.drop(columns= ['quantity'])\n",
        "\n",
        "    #Changing T/F to 1/0\n",
        "    df['permit'] = df['permit']*1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return df\n",
        "\n",
        "df = wrangle(fm_path= 'train_features.csv',\n",
        "             tv_path = 'train_labels.csv')\n",
        "X_test = wrangle(fm_path= 'test_features.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcDORBZHuof0"
      },
      "source": [
        "**Task 1:** Using the above `wrangle` function to read `train_features.csv` and `train_labels.csv` into the DataFrame `df`, and `test_features.csv` into the DataFrame `X_test`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyLt4_y3uof2"
      },
      "source": [
        "# II. Split Data\n",
        "\n",
        "**Task 2:** Split your DataFrame `df` into a feature matrix `X` and the target vector `y`. You want to predict `'status_group'`.\n",
        "\n",
        "**Note:** You won't need to do a train-test split because you'll use cross-validation instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y66g0Y1cuof3"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns = ['status_group'])\n",
        "y = df['status_group']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiveKKoWuof5"
      },
      "source": [
        "# III. Establish Baseline\n",
        "\n",
        "**Task 3:** Since this is a **classification** problem, you should establish a baseline accuracy score. Figure out what is the majority class in `y_train` and what percentage of your training observations it represents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7G6oxD8uof8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d8a2958-a127-4e97-b3ea-8b4acb5a05e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Accuracy Score: 0.5429828068772491\n"
          ]
        }
      ],
      "source": [
        "baseline_acc = y.value_counts(normalize=True).max()\n",
        "print('Baseline Accuracy Score:', baseline_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIdAnB9tuof_"
      },
      "source": [
        "# IV. Build Models\n",
        "\n",
        "**Task 4:** Build a `Pipeline` named `clf_dt`. Your `Pipeline` should include:\n",
        "\n",
        "- an `OrdinalEncoder` transformer for categorical features.\n",
        "- a `SimpleImputer` transformer fot missing values.\n",
        "- a `DecisionTreeClassifier` Predictor.\n",
        "\n",
        "**Note:** Do not train `clf_dt`. You'll do that in a subsequent task. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SQEdOYKN2fKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94HufwsUuogA"
      },
      "outputs": [],
      "source": [
        "clf_dt = make_pipeline(OrdinalEncoder(),\n",
        "                       SimpleImputer(),\n",
        "                       DecisionTreeClassifier(random_state= 42)\n",
        "    \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOTSZIETuogB"
      },
      "source": [
        "**Task 5:** Build a `Pipeline` named `clf_rf`. Your `Pipeline` should include:\n",
        "\n",
        "- an `OrdinalEncoder` transformer for categorical features.\n",
        "- a `SimpleImputer` transformer fot missing values.\n",
        "- a `RandomForestClassifier` predictor.\n",
        "\n",
        "**Note:** Do not train `clf_rf`. You'll do that in a subsequent task. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ga5O1aDLuogB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4fa3227-2d82-4163-9e35-23e51c5f821b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('ordinalencoder',\n",
              "                 OrdinalEncoder(cols=['basin', 'region', 'scheme_management',\n",
              "                                      'permit', 'extraction_type',\n",
              "                                      'extraction_type_class', 'management',\n",
              "                                      'payment', 'payment_type',\n",
              "                                      'water_quality', 'quality_group',\n",
              "                                      'source', 'source_class',\n",
              "                                      'waterpoint_type'],\n",
              "                                mapping=[{'col': 'basin',\n",
              "                                          'data_type': dtype('O'),\n",
              "                                          'mapping': Internal                   1\n",
              "Lake Rukwa                 2\n",
              "Rufiji                     3\n",
              "Wami / Ruvu                4\n",
              "L...\n",
              "unknown        3\n",
              "NaN           -2\n",
              "dtype: int64},\n",
              "                                         {'col': 'waterpoint_type',\n",
              "                                          'data_type': dtype('O'),\n",
              "                                          'mapping': communal standpipe             1\n",
              "hand pump                      2\n",
              "other                          3\n",
              "communal standpipe multiple    4\n",
              "improved spring                5\n",
              "cattle trough                  6\n",
              "dam                            7\n",
              "NaN                           -2\n",
              "dtype: int64}])),\n",
              "                ('simpleimputer', SimpleImputer(strategy='median')),\n",
              "                ('randomforestclassifier',\n",
              "                 RandomForestClassifier(max_depth=20, n_estimators=125,\n",
              "                                        n_jobs=-1, random_state=42))])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "clf_rf = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(strategy= 'median'),\n",
        "    RandomForestClassifier(random_state= 42, n_estimators= 125, max_depth= 20, n_jobs = -1)\n",
        ")\n",
        "\n",
        "clf_rf.fit(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(clf_rf.get_params())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3-ye1FVab3a",
        "outputId": "c87f0cb5-1190-4b95-e2bd-dd267f633d3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['memory',\n",
              " 'ordinalencoder',\n",
              " 'ordinalencoder__cols',\n",
              " 'ordinalencoder__drop_invariant',\n",
              " 'ordinalencoder__handle_missing',\n",
              " 'ordinalencoder__handle_unknown',\n",
              " 'ordinalencoder__mapping',\n",
              " 'ordinalencoder__return_df',\n",
              " 'ordinalencoder__verbose',\n",
              " 'randomforestclassifier',\n",
              " 'randomforestclassifier__bootstrap',\n",
              " 'randomforestclassifier__ccp_alpha',\n",
              " 'randomforestclassifier__class_weight',\n",
              " 'randomforestclassifier__criterion',\n",
              " 'randomforestclassifier__max_depth',\n",
              " 'randomforestclassifier__max_features',\n",
              " 'randomforestclassifier__max_leaf_nodes',\n",
              " 'randomforestclassifier__max_samples',\n",
              " 'randomforestclassifier__min_impurity_decrease',\n",
              " 'randomforestclassifier__min_samples_leaf',\n",
              " 'randomforestclassifier__min_samples_split',\n",
              " 'randomforestclassifier__min_weight_fraction_leaf',\n",
              " 'randomforestclassifier__n_estimators',\n",
              " 'randomforestclassifier__n_jobs',\n",
              " 'randomforestclassifier__oob_score',\n",
              " 'randomforestclassifier__random_state',\n",
              " 'randomforestclassifier__verbose',\n",
              " 'randomforestclassifier__warm_start',\n",
              " 'simpleimputer',\n",
              " 'simpleimputer__add_indicator',\n",
              " 'simpleimputer__copy',\n",
              " 'simpleimputer__fill_value',\n",
              " 'simpleimputer__missing_values',\n",
              " 'simpleimputer__strategy',\n",
              " 'simpleimputer__verbose',\n",
              " 'steps',\n",
              " 'verbose']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H65ANs3wuogC"
      },
      "source": [
        "# V. Check Metrics\n",
        "\n",
        "**Task 6:** Evaluate the performance of both of your classifiers using k-fold cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.drop(columns= ['waterpoint_type_group'], inplace= True)"
      ],
      "metadata": {
        "id": "BlSTiBgZluQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqdVPZwluogD"
      },
      "outputs": [],
      "source": [
        "cv_scores_dt = cross_val_score(clf_dt, X, y, cv = 5, n_jobs= -1)\n",
        "cv_scores_rf = cross_val_score(clf_rf, X, y, cv = 5, n_jobs= -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQ_Y9G1JuogE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "348cd268-43d7-41a2-eb84-f0877fdb5b16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV scores DecisionTreeClassifier\n",
            "[0.74673822 0.7522096  0.75189394 0.74989478 0.75365674]\n",
            "Mean CV accuracy score: 0.7508786543926763\n",
            "STD CV accuracy score: 0.0023929567271821404\n"
          ]
        }
      ],
      "source": [
        "print('CV scores DecisionTreeClassifier')\n",
        "print(cv_scores_dt)\n",
        "print('Mean CV accuracy score:', cv_scores_dt.mean())\n",
        "print('STD CV accuracy score:', cv_scores_dt.std())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bw2yM1X7uogF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eb71121-7001-457d-b611-f327337482c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV score RandomForestClassifier\n",
            "[0.79734848 0.80082071 0.79776936 0.80397727 0.79953699]\n",
            "Mean CV accuracy score: 0.7998905626470607\n",
            "STD CV accuracy score: 0.0023938689101471876\n"
          ]
        }
      ],
      "source": [
        "print('CV score RandomForestClassifier')\n",
        "print(cv_scores_rf)\n",
        "print('Mean CV accuracy score:', cv_scores_rf.mean())\n",
        "print('STD CV accuracy score:', cv_scores_rf.std())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCDtyvkxuogG"
      },
      "source": [
        "# VI. Tune Model\n",
        "\n",
        "**Task 7:** Choose the best performing of your two models and tune its hyperparameters using a `RandomizedSearchCV` named `model`. Make sure that you include cross-validation and that `n_iter` is set to at least `25`.\n",
        "\n",
        "**Note:** If you're not sure which hyperparameters to tune, check the notes from today's guided project and the `sklearn` documentation. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIHuW2GRuogH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee948cfc-c355-491d-affe-98333dc20b77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5,\n",
              "                   estimator=Pipeline(steps=[('ordinalencoder',\n",
              "                                              OrdinalEncoder()),\n",
              "                                             ('simpleimputer', SimpleImputer()),\n",
              "                                             ('randomforestclassifier',\n",
              "                                              RandomForestClassifier(n_jobs=-1,\n",
              "                                                                     random_state=42))]),\n",
              "                   n_iter=50, n_jobs=-1,\n",
              "                   param_distributions={'randomforestclassifier__max_depth': range(5, 50, 5),\n",
              "                                        'randomforestclassifier__n_estimators': range(25, 150, 25),\n",
              "                                        'simpleimputer__strategy': ['mean',\n",
              "                                                                    'median']},\n",
              "                   verbose=1)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "param_grid = {\n",
        "    'simpleimputer__strategy': ['mean', 'median'],\n",
        "    'randomforestclassifier__max_depth': range(5,50,5),\n",
        "    'randomforestclassifier__n_estimators': range(25,150,25),\n",
        "}\n",
        "model = RandomizedSearchCV(\n",
        "    clf_rf,\n",
        "    param_distributions = param_grid,\n",
        "    n_jobs = -1,\n",
        "    cv = 5,\n",
        "    verbose = 1,\n",
        "    n_iter = 50\n",
        ")\n",
        "model.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWpgZrstuogI"
      },
      "source": [
        "**Task 8:** Print out the best score and best params for `model`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfRA3JRjuogJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5f16e43-21b5-445f-b180-c5aa45e41ba8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best score for `model`: 0.8038678597331128\n",
            "Best params for `model`: {'simpleimputer__strategy': 'median', 'randomforestclassifier__n_estimators': 125, 'randomforestclassifier__max_depth': 20}\n"
          ]
        }
      ],
      "source": [
        "best_score = model.best_score_\n",
        "best_params = model.best_params_\n",
        "\n",
        "\n",
        "print('Best score for `model`:', best_score)\n",
        "print('Best params for `model`:', best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3uXbzsMuogJ"
      },
      "source": [
        "# Communicate Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZqqHR80uogK"
      },
      "source": [
        "**Task 9:** Create a DataFrame `submission` whose index is the same as `X_test` and that has one column `'status_group'` with your predictions. Next, save this DataFrame as a CSV file and upload your submissions to our competition site. \n",
        "\n",
        "**Note:** Check the `sample_submission.csv` file on the competition website to make sure your submissions follows the same formatting. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BC0QJowIuogK"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame(data = clf_rf.predict(X_test), index= X_test.index)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "DEyfkEQkla-l",
        "outputId": "4ca2276c-7b5e-41c7-85b6-5d9ef9c0bed2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>37098</th>\n",
              "      <td>non functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14530</th>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62607</th>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46053</th>\n",
              "      <td>non functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47083</th>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26092</th>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>919</th>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47444</th>\n",
              "      <td>non functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61128</th>\n",
              "      <td>non functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8075</th>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11880 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    0\n",
              "id                   \n",
              "37098  non functional\n",
              "14530      functional\n",
              "62607      functional\n",
              "46053  non functional\n",
              "47083      functional\n",
              "...               ...\n",
              "26092      functional\n",
              "919        functional\n",
              "47444  non functional\n",
              "61128  non functional\n",
              "8075       functional\n",
              "\n",
              "[11880 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission.columns = ['status_group']"
      ],
      "metadata": {
        "id": "D6EthQqsmBNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "mDCUpdwpmGMR",
        "outputId": "b5ae9c0e-55f4-4762-95f9-d2f7b3e65c88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>status_group</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>37098</th>\n",
              "      <td>non functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14530</th>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62607</th>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46053</th>\n",
              "      <td>non functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47083</th>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26092</th>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>919</th>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47444</th>\n",
              "      <td>non functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61128</th>\n",
              "      <td>non functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8075</th>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11880 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         status_group\n",
              "id                   \n",
              "37098  non functional\n",
              "14530      functional\n",
              "62607      functional\n",
              "46053  non functional\n",
              "47083      functional\n",
              "...               ...\n",
              "26092      functional\n",
              "919        functional\n",
              "47444  non functional\n",
              "61128  non functional\n",
              "8075       functional\n",
              "\n",
              "[11880 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv('new_submission.csv')\n"
      ],
      "metadata": {
        "id": "EOa3uQW3mG77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('new_submission.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "id": "aiWTvB7xmJvy",
        "outputId": "9e2651b2-8503-441d-e544-16ace0cbf4a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_135b1c21-22df-4fcb-8b5c-f6401cb2b612\", \"new_submission.csv\", 222944)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3ZzgpRUumMN1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "colab": {
      "name": "Copy of LS_DS_223_assignment.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}